# Hi-Def-YOLO: 高精度X光安检目标检测项目

你好！这份文档将帮助你快速了解我们项目的整体思路和代码结构。

## 🚀 项目目标

我们的核心目标是**解决X光安检图像中目标检测的难点**，特别是**严重遮挡**和**微小目标**的识别问题。我们为此设计了一个名为 **Hi-Def-YOLO** 的新框架，旨在大幅提升检测的精度和鲁棒性。

## 🧠 核心思路：从“快速感知”到“精细辨识”

我们的框架模仿了安检专家识别违禁品的过程：首先快速扫视，锁定所有可疑区域；然后，对这些可疑区域进行“放大”和“聚焦”，并结合上下文关系进行最终判断。

为此，我们设计了一个两阶段的“**提议-精炼 (Propose-and-Refine)**”架构：

1.  **第一阶段：候选区提议器 (Proposer)**
    * **执行者**：一个标准的、预训练好的 **YOLOv9** 模型。
    * **任务**：发挥其速度优势，对输入的完整X光图像进行一次快速扫描，找出所有“可能”是目标的区域（候选框）。这一步我们追求的是“宁可错杀，不可放过”。

2.  **第二阶段：高清精炼网络 (Refiner)**
    * **这是我们创新的核心**。它接收第一阶段找出的粗略结果，并利用我们的两个“法宝”对其进行精细化的分析和修正：
    * **法宝一：特征超分模块 (Feature SR Module)**
        * **执行者**：我们合作的**图像超分算法 (Real-ESRGAN)**。
        * **创新应用**：我们不直接在原始图像上做超分（这样太慢），而是将超分算法作用于YOLOv9提取出的**特征图**上。它就像一个“数字放大镜”，对每个候选区域的特征进行高清化，恢复因网络下采样而丢失的细节。
    * **法宝二：Transformer关系精炼头 (Transformer Refiner Head)**
        * **执行者**：一个轻量化的 **Transformer** 模型。
        * **任务**：它接收所有被“高清化”后的物体特征，像一个“推理专家”一样，分析**每一个物体与其他所有物体之间的相互关系**。例如，它可以理解“物体A被物体B遮挡”，从而更准确地推断出物体A的完整形态，有效解决遮挡问题并减少误报。

## 📂 代码框架导览

整个项目是模块化的，关键代码都在 `models` 文件夹下：

* `main.py`
    * **作用**：项目的总入口，负责**训练**模型。运行这个文件就可以开始训练流程。
* `prediction.py`
    * **作用**：用于**预测**。当你训练好一个模型后，用这个脚本来对新的图片进行检测。
* `models/hidef_yolo.py`
    * **核心组装文件**。它像一个“总工程师”，把 YOLOv9、特征超分模块和Transformer头组装成我们最终的 `HiDefYOLO` 模型。
* `models/feature_sr_module.py`
    * **超分模块的封装**。这里存放着将Real-ESRGAN的核心网络（RRDBNet）改造为特征增强器的代码。
* `models/transformer_head.py`
    * **Transformer头的实现**。这里定义了用于关系推理的Transformer Decoder网络。
* `weights/`
    * **权重仓库**。所有预训练模型（比如你的7个Real-ESRGAN模型）都放在这里。
* `dataset/`
    * **数据集文件夹**。OPIXray的图片和标签都应按指定的结构放在这里。

## ⚡️ 如何开始训练

项目使用命令行参数来启动，这使得调整实验设置非常灵活。在项目根目录下打开终端，使用以下指令即可开始训练：

```bash
python main.py --data-path ./dataset/opixray.yaml --epochs 100 --batch-size 4 --lr 0.0001 --sr-weights "RealESRGAN_x4plus.pth"
```

* `--data-path`: 指向数据集的配置文件。
* `--epochs`: 训练的总轮数。
* `--batch-size`: 批次大小。如果遇到显存不足的错误，可以适当调小这个值（例如 `2`）。
* `--sr-weights`: 指定要加载哪个Real-ESRGAN模型权重，可以换成 `weights` 文件夹下的任何一个文件名。

---

希望这份文档能帮助你快速上手。如果你有任何问题，我们随时可以讨论！
