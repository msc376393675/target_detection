import torch
import argparse
from pathlib import Path
from tqdm import tqdm
from torch.utils.data import DataLoader
from utils.datasets import OPIXrayDataset
import os
import torch.nn.functional as F

from models.hidef_yolo import HiDefYOLO



def create_opixray_dataloader(img_dir, label_dir, batch_size, img_size=640):
    """çœŸå®çš„OPIXrayæ•°æ®åŠ è½½å™¨ã€‚"""
    dataset = OPIXrayDataset(img_dir, label_dir, img_size)
    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)

def compute_loss(preds, targets):
    """ä¸€ä¸ªç®€åŒ–çš„æŸå¤±å‡½æ•°å®ç°ã€‚"""
    refined_logits, refined_bbox_deltas = preds

    target_classes = targets[..., 0].long()
    target_boxes = targets[..., 1:]

    # åˆ†ç±»æŸå¤± (åªå¯¹æœ‰ç›®æ ‡çš„è¿›è¡Œè®¡ç®—)
    valid_mask = target_classes > -1 # å‡è®¾-1æ˜¯èƒŒæ™¯/padding
    loss_cls = F.cross_entropy(refined_logits[valid_mask], target_classes[valid_mask])

    # å›å½’æŸå¤± (åªå¯¹æœ‰ç›®æ ‡çš„è¿›è¡Œè®¡ç®—)
    # TODO: refined_bbox_deltaséœ€è¦è½¬æ¢æˆä¸target_boxesç›¸åŒçš„æ ¼å¼
    loss_bbox = F.l1_loss(refined_bbox_deltas[valid_mask], target_boxes[valid_mask])

    return loss_cls + loss_bbox


def train_one_epoch(model, dataloader, optimizer, device, epoch, total_epochs):
    """è®­ç»ƒä¸€ä¸ªå‘¨æœŸçš„å‡½æ•°ã€‚"""
    model.train()  # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
    total_loss = 0
    
    # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦æ¡
    pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{total_epochs} [Training]")
    for images, targets in pbar:
        images = images.to(device)
        targets = targets.to(device)
        
        # æ¸…é›¶æ¢¯åº¦
        optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        # å‡è®¾æ¨¡å‹åœ¨è®­ç»ƒæ—¶ç›´æ¥è¿”å›æŸå¤±
        loss = model(images, targets)
        
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # æ›´æ–°æƒé‡
        optimizer.step()
        
        total_loss += loss.item()
        pbar.set_postfix(loss=f"{loss.item():.4f}")
        
    avg_loss = total_loss / len(dataloader)
    print(f"Epoch {epoch+1} Training Average Loss: {avg_loss:.4f}")
    return avg_loss


@torch.no_grad()
def evaluate(model, dataloader, device):
    """è¯„ä¼°æ¨¡å‹çš„å‡½æ•°ã€‚"""
    model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    print("\nRunning validation...")
    
    for images, targets in tqdm(dataloader, desc="[Validation]"):
        images = images.to(device)
        # åœ¨è¯„ä¼°æ¨¡å¼ä¸‹ï¼Œæ¨¡å‹è¿”å›é¢„æµ‹ç»“æœ
        predictions = model(images)
        # TODO: åœ¨è¿™é‡Œå¤„ç†predictionsï¼Œå¹¶ä¸targetsæ¯”è¾ƒï¼Œè®¡ç®—mAPç­‰æŒ‡æ ‡
        
    print("Validation finished. (mAP calculation logic needs to be implemented)")
    # return validation_metrics 
    return {"mAP": 0.5} # è¿”å›ä¸€ä¸ªè™šæ‹Ÿçš„mAP


def main(args):
    """ä¸»æ‰§è¡Œå‡½æ•°ã€‚"""
    # 1. è®¾ç½®è®¾å¤‡ (CUDA or CPU)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # 2. å‡†å¤‡æ•°æ®é›†
    print("âŒ›ï¸ Loading OPIXray dataset...")
    train_img_dir = os.path.join(args.dataset_root, 'train/train_image')
    train_label_dir = os.path.join(args.dataset_root, 'train/train_annotation')
    train_loader = create_opixray_dataloader(train_img_dir, train_label_dir, args.batch_size)

    val_img_dir = os.path.join(args.dataset_root, 'test/test_image')
    val_label_dir = os.path.join(args.dataset_root, 'test/test_annotation')
    val_loader = create_opixray_dataloader(val_img_dir, val_label_dir, args.batch_size)
    print("âœ… Dataset loaded.")
    
    # 3. æ„å»ºæ¨¡å‹
    # HiDefYOLOå°†è‡ªåŠ¨åŠ è½½æŒ‡å®šçš„YOLOv9å’ŒReal-ESRGANæƒé‡
    model = HiDefYOLO(
        num_classes=args.num_classes,
        sr_in_channels=args.sr_channels,
        feature_dim=args.feature_dim,
        yolov9_variant=args.yolo_weights,
        sr_model_name=args.sr_weights # 
    ).to(device)

    # 4. å®šä¹‰ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
    params_to_optimize = [p for p in model.parameters() if p.requires_grad]
    optimizer = torch.optim.AdamW(params_to_optimize, lr=args.lr, weight_decay=args.weight_decay)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=1e-6)

    # 5. å¼€å§‹è®­ç»ƒå¾ªç¯
    print("\nğŸš€ Starting training for {} epochs...".format(args.epochs))
    for epoch in range(args.epochs):
        train_one_epoch(model, train_loader, optimizer, device, epoch, args.epochs)
        
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # TODO: åœ¨è¿™é‡Œæ·»åŠ ä¿å­˜æ¨¡å‹çš„é€»è¾‘
        torch.save(model.state_dict(), f'hidef_yolo_epoch_{epoch+1}.pt')

    print("\nâœ… Training complete!")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Hi-Def-YOLO Training Script')
    
    # æ•°æ®é›†å’Œæ¨¡å‹è·¯å¾„å‚æ•°
    parser.add_argument('--data-path', type=str, default='./data/opixray.yaml', help='Path to the dataset config file')
    parser.add_argument('--yolo-weights', type=str, default='yolov9-c.pt', help='Path to YOLOv9 pretrained weights')
    parser.add_argument('--sr-weights', type=str, default='RealESRGAN_x4plus.pth', help='Filename of the Real-ESRGAN weights in the ./weights folder')

    # è®­ç»ƒè¶…å‚æ•°
    parser.add_argument('--epochs', type=int, default=100, help='Number of training epochs')
    parser.add_argument('--batch-size', type=int, default=8, help='Batch size for training')
    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate')
    parser.add_argument('--weight-decay', type=float, default=1e-2, help='Weight decay for optimizer')

    # æ¨¡å‹ç»“æ„å‚æ•°
    parser.add_argument('--num-classes', type=int, default=25, help='Number of classes in your dataset (e.g., OPIXray has 25)')
    parser.add_argument('--sr-channels', type=int, default=256, help='Number of input channels for the SR module')
    parser.add_argument('--feature-dim', type=int, default=256, help='Dimension of features for the Transformer head')

    args = parser.parse_args()
    
    # ç¡®ä¿æƒé‡æ–‡ä»¶å¤¹å­˜åœ¨
    if not Path('weights').exists():
        Path('weights').mkdir()
        
    main(args)
