# file: main.py

import torch
import argparse
from pathlib import Path
from tqdm import tqdm

from models.hidef_yolo import HiDefYOLO
# å‡è®¾ä½ å·²ç»å‡†å¤‡å¥½äº†OPIXrayçš„æ•°æ®åŠ è½½å™¨
# from data.dataset import create_opixray_dataloader 

# --- å ä½ç¬¦ï¼šä½ éœ€è¦è‡ªå·±å®ç°è¿™äº› ---
# åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œä½ éœ€è¦æ ¹æ®ä½ çš„æ•°æ®é›†æ ¼å¼æ¥ç¼–å†™æ•°æ®åŠ è½½å™¨å’ŒæŸå¤±å‡½æ•°
def create_opixray_dataloader(path, batch_size):
    """ä¸€ä¸ªæ•°æ®åŠ è½½å™¨çš„å ä½ç¬¦ï¼Œä½ éœ€è¦æ›¿æ¢æˆçœŸå®çš„å®ç°ã€‚"""
    print("âš ï¸ æ³¨æ„: æ­£åœ¨ä½¿ç”¨å ä½ç¬¦æ•°æ®åŠ è½½å™¨ã€‚")
    # æ¨¡æ‹Ÿè¿”å›ä¸€äº›éšæœºæ•°æ®
    dummy_dataset = torch.utils.data.TensorDataset(
        torch.rand(16, 3, 640, 640), # 16å¼ å›¾ç‰‡
        torch.rand(16, 100, 5)        # 16ç»„æ ‡ç­¾ (å‡è®¾æ¯å¼ å›¾æœ€å¤š100ä¸ªç‰©ä½“ï¼Œæ¯ä¸ªç‰©ä½“æœ‰5ä¸ªå€¼: class, x, y, w, h)
    )
    return torch.utils.data.DataLoader(dummy_dataset, batch_size=batch_size, shuffle=True)

def compute_loss(preds, targets):
    """ä¸€ä¸ªæŸå¤±å‡½æ•°çš„å ä½ç¬¦ï¼Œä½ éœ€è¦æ›¿æ¢æˆçœŸå®çš„å®ç°ã€‚"""
    # preds: (refined_logits, refined_bbox_deltas)
    # targets: çœŸå®çš„æ ‡ç­¾
    # çœŸå®çš„æŸå¤±å‡½æ•°éœ€è¦ç»“åˆåˆ†ç±»æŸå¤±(å¦‚Focal Loss)å’Œå›å½’æŸå¤±(å¦‚CIoU Loss)
    return torch.tensor(1.0, requires_grad=True) # è¿”å›ä¸€ä¸ªè™šæ‹Ÿçš„æŸå¤±
# --- å ä½ç¬¦ç»“æŸ ---


def train_one_epoch(model, dataloader, optimizer, device, epoch, total_epochs):
    """è®­ç»ƒä¸€ä¸ªå‘¨æœŸçš„å‡½æ•°ã€‚"""
    model.train()  # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
    total_loss = 0
    
    # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦æ¡
    pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{total_epochs} [Training]")
    for images, targets in pbar:
        images = images.to(device)
        targets = targets.to(device)
        
        # æ¸…é›¶æ¢¯åº¦
        optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­ (åœ¨HiDefYOLOä¸­ï¼Œä½ éœ€è¦å®ç°è®­ç»ƒæ¨¡å¼ä¸‹çš„è¿”å›å€¼)
        # å‡è®¾æ¨¡å‹åœ¨è®­ç»ƒæ—¶ç›´æ¥è¿”å›æŸå¤±
        loss = model(images, targets)
        
        # å¦‚æœæ¨¡å‹ä¸ç›´æ¥è¿”å›lossï¼Œåˆ™éœ€è¦æ‰‹åŠ¨è®¡ç®—
        # refined_logits, refined_bbox_deltas = model(images)
        # loss = compute_loss((refined_logits, refined_bbox_deltas), targets)
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # æ›´æ–°æƒé‡
        optimizer.step()
        
        total_loss += loss.item()
        pbar.set_postfix(loss=f"{loss.item():.4f}")
        
    avg_loss = total_loss / len(dataloader)
    print(f"Epoch {epoch+1} Training Average Loss: {avg_loss:.4f}")
    return avg_loss


@torch.no_grad()
def evaluate(model, dataloader, device):
    """è¯„ä¼°æ¨¡å‹çš„å‡½æ•°ã€‚"""
    model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    print("\nRunning validation...")
    
    # åœ¨è¿™é‡Œï¼Œä½ éœ€è¦åŠ å…¥è®¡ç®—mAPç­‰è¯„ä¼°æŒ‡æ ‡çš„é€»è¾‘
    # è¿™é€šå¸¸æ¯”è¾ƒå¤æ‚ï¼Œå¯èƒ½éœ€è¦å€ŸåŠ©ç¬¬ä¸‰æ–¹åº“
    # è¿™é‡Œæˆ‘ä»¬åªåšä¸€ä¸ªç®€å•çš„å‰å‘ä¼ æ’­æ¼”ç¤º
    for images, targets in tqdm(dataloader, desc="[Validation]"):
        images = images.to(device)
        # åœ¨è¯„ä¼°æ¨¡å¼ä¸‹ï¼Œæ¨¡å‹è¿”å›é¢„æµ‹ç»“æœ
        predictions = model(images)
        # TODO: åœ¨è¿™é‡Œå¤„ç†predictionsï¼Œå¹¶ä¸targetsæ¯”è¾ƒï¼Œè®¡ç®—mAPç­‰æŒ‡æ ‡
        
    print("Validation finished. (mAP calculation logic needs to be implemented)")
    # return validation_metrics 
    return {"mAP": 0.5} # è¿”å›ä¸€ä¸ªè™šæ‹Ÿçš„mAP


def main(args):
    """ä¸»æ‰§è¡Œå‡½æ•°ã€‚"""
    # 1. è®¾ç½®è®¾å¤‡ (CUDA or CPU)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # 2. å‡†å¤‡æ•°æ®é›†
    # ç”¨ä½ çš„çœŸå®æ•°æ®åŠ è½½å™¨æ›¿æ¢è¿™é‡Œçš„å ä½ç¬¦
    train_loader = create_opixray_dataloader(args.data_path, args.batch_size)
    val_loader = create_opixray_dataloader(args.data_path, args.batch_size) # é€šå¸¸éªŒè¯é›†ä¸æ‰“ä¹±
    
    # 3. æ„å»ºæ¨¡å‹
    # HiDefYOLOå°†è‡ªåŠ¨åŠ è½½æŒ‡å®šçš„YOLOv9å’ŒReal-ESRGANæƒé‡
    model = HiDefYOLO(
        num_classes=args.num_classes,
        sr_in_channels=args.sr_channels, # éœ€è¦ä¸YOLOv9 Neckè¾“å‡ºçš„é€šé“æ•°åŒ¹é…
        feature_dim=args.feature_dim,
        yolov9_variant=args.yolo_weights,
        #sr_model_name=args.sr_weights # åœ¨HiDefYOLOçš„__init__ä¸­æ·»åŠ è¿™ä¸ªå‚æ•°æ¥æ¥æ”¶
    ).to(device)

    # 4. å®šä¹‰ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
    # åªä¼˜åŒ–æˆ‘ä»¬è‡ªå·±æ·»åŠ çš„æ¨¡å—çš„å‚æ•°
    params_to_optimize = [p for p in model.parameters() if p.requires_grad]
    optimizer = torch.optim.AdamW(params_to_optimize, lr=args.lr, weight_decay=args.weight_decay)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=1e-6)

    # 5. å¼€å§‹è®­ç»ƒå¾ªç¯
    print("\nğŸš€ Starting training for {} epochs...".format(args.epochs))
    for epoch in range(args.epochs):
        train_one_epoch(model, train_loader, optimizer, device, epoch, args.epochs)
        
        # åœ¨æ¯ä¸ªepochåè¿›è¡Œè¯„ä¼°
        # val_metrics = evaluate(model, val_loader, device)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # TODO: åœ¨è¿™é‡Œæ·»åŠ ä¿å­˜æ¨¡å‹çš„é€»è¾‘
        # torch.save(model.state_dict(), f'hidef_yolo_epoch_{epoch+1}.pt')

    print("\nâœ… Training complete!")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Hi-Def-YOLO Training Script')
    
    # æ•°æ®é›†å’Œæ¨¡å‹è·¯å¾„å‚æ•°
    parser.add_argument('--data-path', type=str, default='./data/opixray.yaml', help='Path to the dataset config file')
    parser.add_argument('--yolo-weights', type=str, default='yolov9-c.pt', help='Path to YOLOv9 pretrained weights')
    parser.add_argument('--sr-weights', type=str, default='RealESRGAN_x4plus.pth', help='Filename of the Real-ESRGAN weights in the ./weights folder')

    # è®­ç»ƒè¶…å‚æ•°
    parser.add_argument('--epochs', type=int, default=100, help='Number of training epochs')
    parser.add_argument('--batch-size', type=int, default=8, help='Batch size for training')
    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate')
    parser.add_argument('--weight-decay', type=float, default=1e-2, help='Weight decay for optimizer')

    # æ¨¡å‹ç»“æ„å‚æ•°
    parser.add_argument('--num-classes', type=int, default=25, help='Number of classes in your dataset (e.g., OPIXray has 25)')
    parser.add_argument('--sr-channels', type=int, default=256, help='Number of input channels for the SR module')
    parser.add_argument('--feature-dim', type=int, default=256, help='Dimension of features for the Transformer head')

    args = parser.parse_args()
    
    # ç¡®ä¿æƒé‡æ–‡ä»¶å¤¹å­˜åœ¨
    if not Path('weights').exists():
        Path('weights').mkdir()
        
    main(args)